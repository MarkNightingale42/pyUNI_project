{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3694bebf-64a4-48b0-9a7b-2b821028577e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\baltt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from measure_time import measure_time\n",
    "\n",
    "import pandas as pd\n",
    "from ast import literal_eval #used for extracting comments (lists stored as strings)\n",
    "\n",
    "import re\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "#--------#\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = re.split(r'[^а-яА-Я]', text) # разбиваем текст на слова\n",
    "    num_words = len(words)\n",
    "    tokens = list()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS not in ['NPRO', 'PREP', 'CONJ', 'PRCL', 'INTJ', 'NUMR']:\n",
    "            tokens.append(p.normal_form)\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "                and token != \" \" \\\n",
    "                and token.strip() not in punctuation]\n",
    "    company_tokens_text_len = len(tokens)\n",
    "\n",
    "    return \" \".join(tokens), company_tokens_text_len, num_words\n",
    "\n",
    "def preprocess_text_in_list(list_):\n",
    "    prepr_list = []\n",
    "    for comment in list_:\n",
    "        prepr_comment = preprocess_text(comment)\n",
    "        prepr_list.append(prepr_comment)\n",
    "    return prepr_list\n",
    "\n",
    "def unpack_comments(comments_list_str):\n",
    "    if comments_list_str[-2:] != \"']\" and comments_list_str[-2:] != \"\\\"]\" and comments_list_str != \"[]\":\n",
    "        last_ap_ind = comments_list_str.rfind(\"'\")\n",
    "        comments_list_str = comments_list_str[:last_ap_ind-2] + \"]\"\n",
    "    return comments_list_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e345a860-67fd-4c51-9cfe-0790f17f9f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Бонч_основная_all_posts_07_02_24.xlsx',\n",
       " 'Бонч_подслушано_all_posts_07_02_24.xlsx',\n",
       " 'Бонч_поступление_all_posts_07_02_24.xlsx',\n",
       " 'ВШЭ_основная_all_posts_07_02_24.xlsx',\n",
       " 'ВШЭ_подслушано_all_posts_07_02_24.xlsx',\n",
       " 'ВШЭ_поступление_all_posts_07_02_24.xlsx',\n",
       " 'ИТМО_основная_all_posts_07_02_24.xlsx',\n",
       " 'ИТМО_подслушано_all_posts_07_02_24.xlsx',\n",
       " 'ИТМО_поступление_all_posts_07_02_24.xlsx',\n",
       " 'ЛЭТИ_основная_all_posts_07_02_24.xlsx',\n",
       " 'ЛЭТИ_подслушано_all_posts_07_02_24.xlsx',\n",
       " 'ЛЭТИ_постулпения_all_posts_07_02_24.xlsx',\n",
       " 'Политех_основная_all_posts_07_02_24.xlsx',\n",
       " 'Политех_подслушано_all_posts_07_02_24.xlsx',\n",
       " 'Политех_поступление_all_posts_07_02_24.xlsx']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "groups_files = os.listdir('Collected')\n",
    "\n",
    "groups_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "906375bc-80df-415a-8fa7-978ad72eb6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Бонч_основная_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 2 minutes 3 seconds\n",
      "Working on Бонч_подслушано_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 0 minutes 21 seconds\n",
      "Working on Бонч_поступление_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 0 minutes 31 seconds\n",
      "Working on ВШЭ_основная_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 1 minutes 19 seconds\n",
      "Working on ВШЭ_подслушано_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 2 minutes 35 seconds\n",
      "Working on ВШЭ_поступление_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 0 minutes 26 seconds\n",
      "Working on ИТМО_основная_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 0 minutes 50 seconds\n",
      "Working on ИТМО_подслушано_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 1 minutes 25 seconds\n",
      "Working on ИТМО_поступление_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 0 minutes 16 seconds\n",
      "Working on ЛЭТИ_основная_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 1 minutes 42 seconds\n",
      "Working on ЛЭТИ_подслушано_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 1 minutes 7 seconds\n",
      "Working on ЛЭТИ_постулпения_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 0 minutes 18 seconds\n",
      "Working on Политех_основная_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 1 minutes 22 seconds\n",
      "Working on Политех_подслушано_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 0 minutes 44 seconds\n",
      "Working on Политех_поступление_all_posts_07_02_24.xlsx\n",
      "Execution time: 0 hours 1 minutes 0 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval #used for extracting comments (lists stored as strings)\n",
    "\n",
    "os.makedirs('Preprocessed', exist_ok = True)\n",
    "\n",
    "years_included = list(map(str, range(2019, 2024)))\n",
    "\n",
    "raw_words_num = 0\n",
    "\n",
    "for group in groups_files:\n",
    "    st = time.time()\n",
    "    print(f'Working on {group}')\n",
    "    group_df = pd.read_excel(f'Collected/{group}')\n",
    "\n",
    "    group_df = group_df[group_df['Дата публикации и время поста'].str[:4].isin(years_included)]\n",
    "    \n",
    "    text_group_df = group_df[['Текст поста']]\n",
    "\n",
    "    text_group_df_preprocessed = text_group_df['Текст поста'].astype(str).apply(preprocess_text)\n",
    "    text_group_df_preprocessed = pd.DataFrame(list(text_group_df_preprocessed), columns = ['text_tokens', 'text_length', 'raw_text_length'])\n",
    "    raw_words_num += text_group_df_preprocessed['raw_text_length'].sum()\n",
    "    prepr_df = pd.concat([group_df, text_group_df_preprocessed[['text_tokens', 'text_length']]], axis=1, join='inner')\n",
    "\n",
    "    prepr_df[['text_tokens', 'text_length']].to_csv(f'Preprocessed/{group[:-5]}.csv')\n",
    "    measure_time(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33483726-d3c1-4642-8328-9b482a42a88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6321028"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_words_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
